Assignment1:
# UNQ_C1 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)
# GRADED FUNCTION: one_step_attention

def one_step_attention(a, s_prev):
    """
    Performs one step of attention: Outputs a context vector computed as a dot product of the attention weights
    "alphas" and the hidden states "a" of the Bi-LSTM.
    
    Arguments:
    a -- hidden state output of the Bi-LSTM, numpy-array of shape (m, Tx, 2*n_a)
    s_prev -- previous hidden state of the (post-attention) LSTM, numpy-array of shape (m, n_s)
    
    Returns:
    context -- context vector, input of the next (post-attention) LSTM cell
    """
    
    ### START CODE HERE ###
    # Use repeator to repeat s_prev to be of shape (m, Tx, n_s) so that you can concatenate it with all hidden states "a" (≈ 1 line)
    s_prev = repeator(s_prev)
    # Use concatenator to concatenate a and s_prev on the last axis (≈ 1 line)
    # For grading purposes, please list 'a' first and 's_prev' second, in this order.
    concat = concatenator([a,s_prev])
    # Use densor1 to propagate concat through a small fully-connected neural network to compute the "intermediate energies" variable e. (≈1 lines)
    e = densor1(concat)
    # Use densor2 to propagate e through a small fully-connected neural network to compute the "energies" variable energies. (≈1 lines)
    energies = densor2(e)
    # Use "activator" on "energies" to compute the attention weights "alphas" (≈ 1 line)
    alphas = activator(energies)
    # Use dotor together with "alphas" and "a", in this order, to compute the context vector to be given to the next (post-attention) LSTM-cell (≈ 1 line)
    context = dotor([alphas,a])
    ### END CODE HERE ###
    
    return context



# UNQ_C2 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)
# GRADED FUNCTION: model

def modelf(Tx, Ty, n_a, n_s, human_vocab_size, machine_vocab_size=None):
    """
    Arguments:
    Tx -- length of the input sequence
    Ty -- length of the output sequence
    n_a -- hidden state size of the Bi-LSTM
    n_s -- hidden state size of the post-attention LSTM
    human_vocab_size -- size of the python dictionary "human_vocab"
    machine_vocab_size -- integer, optional, size of the python dictionary "machine_vocab"
                          This is not being used

    Returns:
    model -- Keras model instance
    """
    
    # Define the inputs of your model with a shape (Tx, human_vocab_size)
    # Define s0 (initial hidden state) and c0 (initial cell state)
    # for the decoder LSTM with shape (n_s,)
    X = Input(shape=(Tx, human_vocab_size))
    # initial hidden state
    s0 = Input(shape=(n_s,), name='s0')
    # initial cell state
    c0 = Input(shape=(n_s,), name='c0')
    # hidden state
    s = s0
    # cell state
    c = c0
    
    # Initialize empty list of outputs
    outputs = []
    
    ### START CODE HERE ###
    
    # Step 1: Define your pre-attention Bi-LSTM. (≈ 1 line)
    a = Bidirectional(LSTM(n_a, return_sequences=True))(X)
    
    # Step 2: Iterate for Ty steps
    for t in range(Ty):
    
        # Step 2.A: Perform one step of the attention mechanism to get back the context vector at step t (≈ 1 line)
        context = one_step_attention(a,s)
        
        # Step 2.B: Apply the post-attention LSTM cell to the "context" vector. (≈ 1 line)
        # Don't forget to pass: initial_state = [hidden state, cell state] 
        # Remember: s = hidden state, c = cell state
        _, s, c = post_activation_LSTM_cell(context, initial_state=[s,c])
        
        # Step 2.C: Apply Dense layer to the hidden state output of the post-attention LSTM (≈ 1 line)
        out = output_layer(s)
        
        # Step 2.D: Append "out" to the "outputs" list (≈ 1 line)
        outputs.append(out)
    
    # Step 3: Create model instance taking three inputs and returning the list of outputs. (≈ 1 line)
    model = Model(inputs=[X,s0,c0], outputs=outputs)
    
    ### END CODE HERE ###
    
    return model



### START CODE HERE ### (≈2 lines)
opt = Adam(lr=.005, beta_1=.9, beta_2=.999, decay=.01) # Adam(...) 
model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])
### END CODE HERE ###



Assignment2:
  # UNQ_C1
  # GRADED FUNCTION: is_overlapping
  
  def is_overlapping(segment_time, previous_segments):
      """
      Checks if the time of a segment overlaps with the times of existing segments.
      
      Arguments:
      segment_time -- a tuple of (segment_start, segment_end) for the new segment
      previous_segments -- a list of tuples of (segment_start, segment_end) for the existing segments
      
      Returns:
      True if the time segment overlaps with any of the existing segments, False otherwise
      """
      
      segment_start, segment_end = segment_time
      
      ### START CODE HERE ### (≈ 4 lines)
      # Step 1: Initialize overlap as a "False" flag. (≈ 1 line)
      overlap = False
      
      # Step 2: loop over the previous_segments start and end times.
      # Compare start/end times and set the flag to True if there is an overlap (≈ 3 lines)
      for previous_start, previous_end in previous_segments:
          if segment_start <= previous_end and previous_start <= segment_end:
              overlap = True
              break
      ### END CODE HERE ###
  
      return overlap
  
  
  
  # UNQ_C2
  # GRADED FUNCTION: insert_audio_clip
  
  def insert_audio_clip(background, audio_clip, previous_segments):
      """
      Insert a new audio segment over the background noise at a random time step, ensuring that the 
      audio segment does not overlap with existing segments.
      
      Arguments:
      background -- a 10 second background audio recording.  
      audio_clip -- the audio clip to be inserted/overlaid. 
      previous_segments -- times where audio segments have already been placed
      
      Returns:
      new_background -- the updated background audio
      """
      
      # Get the duration of the audio clip in ms
      segment_ms = len(audio_clip)
      
      ### START CODE HERE ### 
      # Step 1: Use one of the helper functions to pick a random time segment onto which to insert 
      # the new audio clip. (≈ 1 line)
      segment_time = get_random_time_segment(segment_ms)
      
      # Step 2: Check if the new segment_time overlaps with one of the previous_segments. If so, keep 
      # picking new segment_time at random until it doesn't overlap. To avoid an endless loop
      # we retry 5 times(≈ 2 lines)
      retry = 5 
      while is_overlapping(segment_time, previous_segments) and retry >= 0:
          segment_time = get_random_time_segment(segment_ms)
          retry = retry - 1
      ### END CODE HERE ###
          #print(segment_time)
      # if last try is not overlaping, insert it to the background
      if not is_overlapping(segment_time, previous_segments):
      ### START CODE HERE ### 
          # Step 3: Append the new segment_time to the list of previous_segments (≈ 1 line)
          previous_segments.append(segment_time)
      ### END CODE HERE ###
          # Step 4: Superpose audio segment and background
          new_background = background.overlay(audio_clip, position = segment_time[0])
      else:
          #print("Timeouted")
          new_background = background
          segment_time = (10000, 10000)
      
      return new_background, segment_time
  
  
  
  # UNQ_C3
  # GRADED FUNCTION: insert_ones
  
  def insert_ones(y, segment_end_ms):
      """
      Update the label vector y. The labels of the 50 output steps strictly after the end of the segment 
      should be set to 1. By strictly we mean that the label of segment_end_y should be 0 while, the
      50 following labels should be ones.
      
      
      Arguments:
      y -- numpy array of shape (1, Ty), the labels of the training example
      segment_end_ms -- the end time of the segment in ms
      
      Returns:
      y -- updated labels
      """
      _, Ty = y.shape
      
      # duration of the background (in terms of spectrogram time-steps)
      segment_end_y = int(segment_end_ms * Ty / 10000.0)
      
      if segment_end_y < Ty:
          # Add 1 to the correct index in the background label (y)
          ### START CODE HERE ### (≈ 3 lines)
          for i in range(segment_end_y + 1, segment_end_y + 51):
              if i < Ty:
                  y[0, i] = 1.0
          ### END CODE HERE ###
      
      return y
  
  
  
  # UNQ_C4
  # GRADED FUNCTION: create_training_example
  
  def create_training_example(background, activates, negatives, Ty):
      """
      Creates a training example with a given background, activates, and negatives.
      
      Arguments:
      background -- a 10 second background audio recording
      activates -- a list of audio segments of the word "activate"
      negatives -- a list of audio segments of random words that are not "activate"
      Ty -- The number of time steps in the output
  
      Returns:
      x -- the spectrogram of the training example
      y -- the label at each time step of the spectrogram
      """
      
      # Make background quieter
      background = background - 20
  
      ### START CODE HERE ###
      # Step 1: Initialize y (label vector) of zeros (≈ 1 line)
      y = np.zeros((1, Ty))
  
      # Step 2: Initialize segment times as empty list (≈ 1 line)
      previous_segments = []
      ### END CODE HERE ###
      
      # Select 0-4 random "activate" audio clips from the entire list of "activates" recordings
      number_of_activates = np.random.randint(0, 5)
      random_indices = np.random.randint(len(activates), size=number_of_activates)
      random_activates = [activates[i] for i in random_indices]
      
      ### START CODE HERE ### (≈ 3 lines)
      # Step 3: Loop over randomly selected "activate" clips and insert in background
      for one_random_activate in random_activates:
          # Insert the audio clip on the background
          background, segment_time = insert_audio_clip(background, one_random_activate, previous_segments)
          # Retrieve segment_start and segment_end from segment_time
          segment_start, segment_end = segment_time
          # Insert labels in "y" at segment_end
          y = insert_ones(y,segment_end)
      ### END CODE HERE ###
  
      # Select 0-2 random negatives audio recordings from the entire list of "negatives" recordings
      number_of_negatives = np.random.randint(0, 3)
      random_indices = np.random.randint(len(negatives), size=number_of_negatives)
      random_negatives = [negatives[i] for i in random_indices]
  
      ### START CODE HERE ### (≈ 2 lines)
      # Step 4: Loop over randomly selected negative clips and insert in background
      for random_negative in random_negatives:
          # Insert the audio clip on the background 
          background, _ = insert_audio_clip(background, random_negative, previous_segments)
      ### END CODE HERE ###
      
      # Standardize the volume of the audio clip 
      background = match_target_amplitude(background, -20.0)
  
      # Export new training example 
      file_handle = background.export("train" + ".wav", format="wav")
      
      # Get and plot spectrogram of the new recording (background with superposition of positive and negatives)
      x = graph_spectrogram("train.wav")
      
      return x, y
  
  
  
  # UNQ_C5
  # GRADED FUNCTION: modelf
  
  def modelf(input_shape):
      """
      Function creating the model's graph in Keras.
      
      Argument:
      input_shape -- shape of the model's input data (using Keras conventions)
  
      Returns:
      model -- Keras model instance
      """
      
      X_input = Input(shape = input_shape)
      
      ### START CODE HERE ###
      
      # Step 1: CONV layer (≈4 lines)
      # Add a Conv1D with 196 units, kernel size of 15 and stride of 4
      X = Conv1D(filters=196, kernel_size=15, strides=4)(X_input)
      # Batch normalization
      X = BatchNormalization()(X)
      # ReLu activation
      X = Activation('relu')(X)
      # dropout (use 0.8)
      X = Dropout(.8)(X)                                  
  
      # Step 2: First GRU Layer (≈4 lines)
      # GRU (use 128 units and return the sequences)
      X = GRU(units=128, return_sequences=True)(X)
      # dropout (use 0.8)
      X = Dropout(.8)(X)
      # Batch normalization.
      X = BatchNormalization()(X)                           
      
      # Step 3: Second GRU Layer (≈4 lines)
      # GRU (use 128 units and return the sequences)
      X = GRU(units=128, return_sequences=True)(X)
      # dropout (use 0.8)
      X = Dropout(.8)(X)       
      # Batch normalization
      X = BatchNormalization()(X)
      # dropout (use 0.8)
      X = Dropout(0.8)(X)                                  
      
      # Step 4: Time-distributed dense layer (≈1 line)
      # TimeDistributed  with sigmoid activation 
      X = TimeDistributed(Dense(1, activation='sigmoid'))(X)
  
      ### END CODE HERE ###
  
      model = Model(inputs = X_input, outputs = X)
      
      return model  
